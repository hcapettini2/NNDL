{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6844d923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hilar\\anaconda3\\envs\\NNDL_torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "##IMPORTS\n",
    "#Basics\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os # create directories in the local filesystem\n",
    "from tqdm import tqdm # plot progress bars\n",
    "import plotly.express as px\n",
    "\n",
    "#PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import  DataLoader\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Pytoprch lightning\n",
    "\n",
    "\n",
    "#For Optuna (Hyperparameters search)\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# For latent space exploration\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Models definitions and training models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affc598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility (PyTorch, Python, Numpy)\n",
    "matricola = 2013031\n",
    "torch.manual_seed(matricola)\n",
    "random.seed(matricola)\n",
    "np.random.seed(matricola)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68476c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download the data and create dataset\n",
    "data_dir = '../dataset'\n",
    "# With these commands the train and test datasets, respectively, are downloaded \n",
    "# automatically and stored in the local \"data_dir\" directory.\n",
    "train_dataset = torchvision.datasets.FashionMNIST(data_dir, train=True, download=False)\n",
    "test_dataset  = torchvision.datasets.FashionMNIST(data_dir, train=False, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ca8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case the train_transform and test_transform are the same, \n",
    "# but we keep them separate for potential future updates\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Set the train transform\n",
    "train_dataset.transform = train_transform\n",
    "# Set the test transform\n",
    "test_dataset.transform = test_transform\n",
    "\n",
    "### Define train dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "### Define test dataloader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286a00e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824b32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a1a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7829079",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7844ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_space_dim = 2\n",
    "max_epochs        = 10\n",
    "learning_rate     = 1e-3\n",
    "regularization    = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9228670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the autoencoder\n",
    "AE = model.Autoencoder(encoded_space_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e502af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the loss function for reconstruction\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "params_to_optimize = [\n",
    "    {'params': AE.encoder.parameters()},\n",
    "    {'params': AE.decoder.parameters()}\n",
    "]\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=learning_rate, weight_decay=regularization)\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "#Send model to device\n",
    "AE.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e062a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss = AE.training_cycle(device,\n",
    "                                train_dataloader,\n",
    "                                test_dataloader,\n",
    "                                loss_fn,\n",
    "                                optim,\n",
    "                                max_epochs,\n",
    "                                test_dataset,\n",
    "                                encoded_space_dim,\n",
    "                                plot = True,\n",
    "                                keep_plots = False,\n",
    "                                keep_model=False,\n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f1591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a9f269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85cd666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Network Architectures\n",
    "The following are the discriminator and generator architectures\n",
    "\"\"\"\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.activation = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return nn.Sigmoid()(x)\n",
    "\n",
    "\n",
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 784)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        return nn.Tanh()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821d37e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determine if any GPUs are available\n",
    "\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Hyperparameter settings\n",
    "\"\"\"\n",
    "epochs = 100\n",
    "lr = 2e-4\n",
    "batch_size = 64\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a89991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "G = generator().to(device)\n",
    "D = discriminator().to(device)\n",
    "\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f29fc992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Image transformation and dataloader creation\n",
    "# Note that we are training generation and not classification, and hence\n",
    "# only the train_loader is loaded\n",
    "# \"\"\"\n",
    "# # Transform\n",
    "# transform = transforms.Compose([transforms.ToTensor(),\n",
    "#                                 transforms.Normalize((0.5,), (0.5,))])\n",
    "# # Load data\n",
    "# train_set = datasets.MNIST('mnist/', train=True, download=True, transform=transform)\n",
    "# train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2016830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Iteration 100: discriminator_loss 0.673 generator_loss 0.939\n",
      "Epoch 0 Iteration 200: discriminator_loss 0.665 generator_loss 0.764\n",
      "Epoch 0 Iteration 235: discriminator_loss 0.631 generator_loss 0.782\n",
      "Epoch 1 Iteration 100: discriminator_loss 0.659 generator_loss 1.100\n",
      "Epoch 1 Iteration 200: discriminator_loss 0.617 generator_loss 0.787\n",
      "Epoch 1 Iteration 235: discriminator_loss 0.645 generator_loss 0.720\n",
      "Epoch 2 Iteration 100: discriminator_loss 0.642 generator_loss 0.816\n",
      "Epoch 2 Iteration 200: discriminator_loss 0.696 generator_loss 0.691\n",
      "Epoch 2 Iteration 235: discriminator_loss 0.682 generator_loss 0.849\n",
      "Epoch 3 Iteration 100: discriminator_loss 0.534 generator_loss 0.848\n",
      "Epoch 3 Iteration 200: discriminator_loss 0.799 generator_loss 0.881\n",
      "Epoch 3 Iteration 235: discriminator_loss 0.754 generator_loss 0.964\n",
      "Epoch 4 Iteration 100: discriminator_loss 0.554 generator_loss 0.872\n",
      "Epoch 4 Iteration 200: discriminator_loss 0.677 generator_loss 0.787\n",
      "Epoch 4 Iteration 235: discriminator_loss 0.612 generator_loss 0.944\n",
      "Epoch 5 Iteration 100: discriminator_loss 0.678 generator_loss 1.025\n",
      "Epoch 5 Iteration 200: discriminator_loss 0.627 generator_loss 0.907\n",
      "Epoch 5 Iteration 235: discriminator_loss 0.640 generator_loss 0.943\n",
      "Epoch 6 Iteration 100: discriminator_loss 0.579 generator_loss 1.106\n",
      "Epoch 6 Iteration 200: discriminator_loss 0.692 generator_loss 1.012\n",
      "Epoch 6 Iteration 235: discriminator_loss 0.681 generator_loss 0.962\n",
      "Epoch 7 Iteration 100: discriminator_loss 0.594 generator_loss 0.957\n",
      "Epoch 7 Iteration 200: discriminator_loss 0.618 generator_loss 0.921\n",
      "Epoch 7 Iteration 235: discriminator_loss 0.719 generator_loss 0.793\n",
      "Epoch 8 Iteration 100: discriminator_loss 0.636 generator_loss 0.968\n",
      "Epoch 8 Iteration 200: discriminator_loss 0.626 generator_loss 0.950\n",
      "Epoch 8 Iteration 235: discriminator_loss 0.696 generator_loss 0.799\n",
      "Epoch 9 Iteration 100: discriminator_loss 0.658 generator_loss 0.854\n",
      "Epoch 9 Iteration 200: discriminator_loss 0.620 generator_loss 0.848\n",
      "Epoch 9 Iteration 235: discriminator_loss 0.640 generator_loss 0.866\n",
      "Model saved.\n",
      "Epoch 10 Iteration 100: discriminator_loss 0.671 generator_loss 0.878\n",
      "Epoch 10 Iteration 200: discriminator_loss 0.651 generator_loss 0.931\n",
      "Epoch 10 Iteration 235: discriminator_loss 0.669 generator_loss 0.841\n",
      "Epoch 11 Iteration 100: discriminator_loss 0.638 generator_loss 0.773\n",
      "Epoch 11 Iteration 200: discriminator_loss 0.639 generator_loss 0.868\n",
      "Epoch 11 Iteration 235: discriminator_loss 0.651 generator_loss 0.761\n",
      "Epoch 12 Iteration 100: discriminator_loss 0.635 generator_loss 0.828\n",
      "Epoch 12 Iteration 200: discriminator_loss 0.645 generator_loss 0.846\n",
      "Epoch 12 Iteration 235: discriminator_loss 0.641 generator_loss 0.835\n",
      "Epoch 13 Iteration 100: discriminator_loss 0.676 generator_loss 0.823\n",
      "Epoch 13 Iteration 200: discriminator_loss 0.664 generator_loss 0.814\n",
      "Epoch 13 Iteration 235: discriminator_loss 0.621 generator_loss 0.821\n",
      "Epoch 14 Iteration 100: discriminator_loss 0.660 generator_loss 0.809\n",
      "Epoch 14 Iteration 200: discriminator_loss 0.670 generator_loss 0.869\n",
      "Epoch 14 Iteration 235: discriminator_loss 0.649 generator_loss 0.804\n",
      "Epoch 15 Iteration 100: discriminator_loss 0.647 generator_loss 0.789\n",
      "Epoch 15 Iteration 200: discriminator_loss 0.677 generator_loss 0.783\n",
      "Epoch 15 Iteration 235: discriminator_loss 0.652 generator_loss 0.869\n",
      "Epoch 16 Iteration 100: discriminator_loss 0.672 generator_loss 0.816\n",
      "Epoch 16 Iteration 200: discriminator_loss 0.670 generator_loss 0.787\n",
      "Epoch 16 Iteration 235: discriminator_loss 0.684 generator_loss 0.823\n",
      "Epoch 17 Iteration 100: discriminator_loss 0.690 generator_loss 0.847\n",
      "Epoch 17 Iteration 200: discriminator_loss 0.687 generator_loss 0.806\n",
      "Epoch 17 Iteration 235: discriminator_loss 0.682 generator_loss 0.806\n",
      "Epoch 18 Iteration 100: discriminator_loss 0.674 generator_loss 0.782\n",
      "Epoch 18 Iteration 200: discriminator_loss 0.665 generator_loss 0.804\n",
      "Epoch 18 Iteration 235: discriminator_loss 0.679 generator_loss 0.712\n",
      "Epoch 19 Iteration 100: discriminator_loss 0.692 generator_loss 0.746\n",
      "Epoch 19 Iteration 200: discriminator_loss 0.699 generator_loss 0.804\n",
      "Epoch 19 Iteration 235: discriminator_loss 0.689 generator_loss 0.805\n",
      "Model saved.\n",
      "Epoch 20 Iteration 100: discriminator_loss 0.690 generator_loss 0.777\n",
      "Epoch 20 Iteration 200: discriminator_loss 0.707 generator_loss 0.787\n",
      "Epoch 20 Iteration 235: discriminator_loss 0.679 generator_loss 0.790\n",
      "Epoch 21 Iteration 100: discriminator_loss 0.684 generator_loss 0.778\n",
      "Epoch 21 Iteration 200: discriminator_loss 0.707 generator_loss 0.801\n",
      "Epoch 21 Iteration 235: discriminator_loss 0.690 generator_loss 0.734\n",
      "Epoch 22 Iteration 100: discriminator_loss 0.696 generator_loss 0.789\n",
      "Epoch 22 Iteration 200: discriminator_loss 0.723 generator_loss 0.784\n",
      "Epoch 22 Iteration 235: discriminator_loss 0.699 generator_loss 0.696\n",
      "Epoch 23 Iteration 100: discriminator_loss 0.669 generator_loss 0.830\n",
      "Epoch 23 Iteration 200: discriminator_loss 0.695 generator_loss 0.808\n",
      "Epoch 23 Iteration 235: discriminator_loss 0.689 generator_loss 0.735\n",
      "Epoch 24 Iteration 100: discriminator_loss 0.666 generator_loss 0.818\n",
      "Epoch 24 Iteration 200: discriminator_loss 0.704 generator_loss 0.750\n",
      "Epoch 24 Iteration 235: discriminator_loss 0.684 generator_loss 0.773\n",
      "Epoch 25 Iteration 100: discriminator_loss 0.675 generator_loss 0.769\n",
      "Epoch 25 Iteration 200: discriminator_loss 0.683 generator_loss 0.821\n",
      "Epoch 25 Iteration 235: discriminator_loss 0.667 generator_loss 0.757\n",
      "Epoch 26 Iteration 100: discriminator_loss 0.691 generator_loss 0.743\n",
      "Epoch 26 Iteration 200: discriminator_loss 0.678 generator_loss 0.773\n",
      "Epoch 26 Iteration 235: discriminator_loss 0.673 generator_loss 0.831\n",
      "Epoch 27 Iteration 100: discriminator_loss 0.694 generator_loss 0.786\n",
      "Epoch 27 Iteration 200: discriminator_loss 0.716 generator_loss 0.737\n",
      "Epoch 27 Iteration 235: discriminator_loss 0.719 generator_loss 0.737\n",
      "Epoch 28 Iteration 100: discriminator_loss 0.671 generator_loss 0.854\n",
      "Epoch 28 Iteration 200: discriminator_loss 0.637 generator_loss 0.852\n",
      "Epoch 28 Iteration 235: discriminator_loss 0.693 generator_loss 0.781\n",
      "Epoch 29 Iteration 100: discriminator_loss 0.678 generator_loss 0.803\n",
      "Epoch 29 Iteration 200: discriminator_loss 0.669 generator_loss 0.769\n",
      "Epoch 29 Iteration 235: discriminator_loss 0.693 generator_loss 0.715\n",
      "Model saved.\n",
      "Epoch 30 Iteration 100: discriminator_loss 0.670 generator_loss 0.779\n",
      "Epoch 30 Iteration 200: discriminator_loss 0.680 generator_loss 0.743\n",
      "Epoch 30 Iteration 235: discriminator_loss 0.696 generator_loss 0.756\n",
      "Epoch 31 Iteration 100: discriminator_loss 0.659 generator_loss 0.768\n",
      "Epoch 31 Iteration 200: discriminator_loss 0.675 generator_loss 0.799\n",
      "Epoch 31 Iteration 235: discriminator_loss 0.695 generator_loss 0.716\n",
      "Epoch 32 Iteration 100: discriminator_loss 0.682 generator_loss 0.743\n",
      "Epoch 32 Iteration 200: discriminator_loss 0.668 generator_loss 0.752\n",
      "Epoch 32 Iteration 235: discriminator_loss 0.694 generator_loss 0.715\n",
      "Epoch 33 Iteration 100: discriminator_loss 0.676 generator_loss 0.779\n",
      "Epoch 33 Iteration 200: discriminator_loss 0.688 generator_loss 0.738\n",
      "Epoch 33 Iteration 235: discriminator_loss 0.687 generator_loss 0.779\n",
      "Epoch 34 Iteration 100: discriminator_loss 0.688 generator_loss 0.787\n",
      "Epoch 34 Iteration 200: discriminator_loss 0.688 generator_loss 0.783\n",
      "Epoch 34 Iteration 235: discriminator_loss 0.699 generator_loss 0.707\n",
      "Epoch 35 Iteration 100: discriminator_loss 0.674 generator_loss 0.753\n",
      "Epoch 35 Iteration 200: discriminator_loss 0.697 generator_loss 0.762\n",
      "Epoch 35 Iteration 235: discriminator_loss 0.695 generator_loss 0.713\n",
      "Epoch 36 Iteration 100: discriminator_loss 0.704 generator_loss 0.756\n",
      "Epoch 36 Iteration 200: discriminator_loss 0.739 generator_loss 0.705\n",
      "Epoch 36 Iteration 235: discriminator_loss 0.692 generator_loss 0.791\n",
      "Epoch 37 Iteration 100: discriminator_loss 0.687 generator_loss 0.780\n",
      "Epoch 37 Iteration 200: discriminator_loss 0.719 generator_loss 0.735\n",
      "Epoch 37 Iteration 235: discriminator_loss 0.652 generator_loss 0.845\n",
      "Epoch 38 Iteration 100: discriminator_loss 0.666 generator_loss 0.782\n",
      "Epoch 38 Iteration 200: discriminator_loss 0.718 generator_loss 0.701\n",
      "Epoch 38 Iteration 235: discriminator_loss 0.683 generator_loss 0.680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Iteration 100: discriminator_loss 0.691 generator_loss 0.729\n",
      "Epoch 39 Iteration 200: discriminator_loss 0.674 generator_loss 0.762\n",
      "Epoch 39 Iteration 235: discriminator_loss 0.660 generator_loss 0.809\n",
      "Model saved.\n",
      "Epoch 40 Iteration 100: discriminator_loss 0.686 generator_loss 0.758\n",
      "Epoch 40 Iteration 200: discriminator_loss 0.695 generator_loss 0.752\n",
      "Epoch 40 Iteration 235: discriminator_loss 0.691 generator_loss 0.691\n",
      "Epoch 41 Iteration 100: discriminator_loss 0.695 generator_loss 0.777\n",
      "Epoch 41 Iteration 200: discriminator_loss 0.712 generator_loss 0.720\n",
      "Epoch 41 Iteration 235: discriminator_loss 0.714 generator_loss 0.734\n",
      "Epoch 42 Iteration 100: discriminator_loss 0.679 generator_loss 0.779\n",
      "Epoch 42 Iteration 200: discriminator_loss 0.711 generator_loss 0.750\n",
      "Epoch 42 Iteration 235: discriminator_loss 0.685 generator_loss 0.731\n",
      "Epoch 43 Iteration 100: discriminator_loss 0.714 generator_loss 0.759\n",
      "Epoch 43 Iteration 200: discriminator_loss 0.692 generator_loss 0.772\n",
      "Epoch 43 Iteration 235: discriminator_loss 0.701 generator_loss 0.745\n",
      "Epoch 44 Iteration 100: discriminator_loss 0.670 generator_loss 0.760\n",
      "Epoch 44 Iteration 200: discriminator_loss 0.698 generator_loss 0.754\n",
      "Epoch 44 Iteration 235: discriminator_loss 0.661 generator_loss 0.792\n",
      "Epoch 45 Iteration 100: discriminator_loss 0.700 generator_loss 0.687\n",
      "Epoch 45 Iteration 200: discriminator_loss 0.729 generator_loss 0.736\n",
      "Epoch 45 Iteration 235: discriminator_loss 0.695 generator_loss 0.707\n",
      "Epoch 46 Iteration 100: discriminator_loss 0.706 generator_loss 0.770\n",
      "Epoch 46 Iteration 200: discriminator_loss 0.678 generator_loss 0.783\n",
      "Epoch 46 Iteration 235: discriminator_loss 0.656 generator_loss 0.761\n",
      "Epoch 47 Iteration 100: discriminator_loss 0.688 generator_loss 0.734\n",
      "Epoch 47 Iteration 200: discriminator_loss 0.680 generator_loss 0.738\n",
      "Epoch 47 Iteration 235: discriminator_loss 0.685 generator_loss 0.687\n",
      "Epoch 48 Iteration 100: discriminator_loss 0.672 generator_loss 0.744\n",
      "Epoch 48 Iteration 200: discriminator_loss 0.667 generator_loss 0.833\n",
      "Epoch 48 Iteration 235: discriminator_loss 0.698 generator_loss 0.674\n",
      "Epoch 49 Iteration 100: discriminator_loss 0.707 generator_loss 0.718\n",
      "Epoch 49 Iteration 200: discriminator_loss 0.689 generator_loss 0.763\n",
      "Epoch 49 Iteration 235: discriminator_loss 0.694 generator_loss 0.687\n",
      "Model saved.\n",
      "Epoch 50 Iteration 100: discriminator_loss 0.711 generator_loss 0.708\n",
      "Epoch 50 Iteration 200: discriminator_loss 0.689 generator_loss 0.739\n",
      "Epoch 50 Iteration 235: discriminator_loss 0.701 generator_loss 0.715\n",
      "Epoch 51 Iteration 100: discriminator_loss 0.680 generator_loss 0.785\n",
      "Epoch 51 Iteration 200: discriminator_loss 0.686 generator_loss 0.795\n",
      "Epoch 51 Iteration 235: discriminator_loss 0.716 generator_loss 0.713\n",
      "Epoch 52 Iteration 100: discriminator_loss 0.697 generator_loss 0.689\n",
      "Epoch 52 Iteration 200: discriminator_loss 0.679 generator_loss 0.802\n",
      "Epoch 52 Iteration 235: discriminator_loss 0.684 generator_loss 0.757\n",
      "Epoch 53 Iteration 100: discriminator_loss 0.672 generator_loss 0.788\n",
      "Epoch 53 Iteration 200: discriminator_loss 0.694 generator_loss 0.738\n",
      "Epoch 53 Iteration 235: discriminator_loss 0.705 generator_loss 0.759\n",
      "Epoch 54 Iteration 100: discriminator_loss 0.685 generator_loss 0.761\n",
      "Epoch 54 Iteration 200: discriminator_loss 0.684 generator_loss 0.746\n",
      "Epoch 54 Iteration 235: discriminator_loss 0.713 generator_loss 0.760\n",
      "Epoch 55 Iteration 100: discriminator_loss 0.696 generator_loss 0.718\n",
      "Epoch 55 Iteration 200: discriminator_loss 0.690 generator_loss 0.715\n",
      "Epoch 55 Iteration 235: discriminator_loss 0.677 generator_loss 0.758\n",
      "Epoch 56 Iteration 100: discriminator_loss 0.684 generator_loss 0.743\n",
      "Epoch 56 Iteration 200: discriminator_loss 0.709 generator_loss 0.721\n",
      "Epoch 56 Iteration 235: discriminator_loss 0.695 generator_loss 0.762\n",
      "Epoch 57 Iteration 100: discriminator_loss 0.675 generator_loss 0.806\n",
      "Epoch 57 Iteration 200: discriminator_loss 0.679 generator_loss 0.801\n",
      "Epoch 57 Iteration 235: discriminator_loss 0.707 generator_loss 0.715\n",
      "Epoch 58 Iteration 100: discriminator_loss 0.674 generator_loss 0.783\n",
      "Epoch 58 Iteration 200: discriminator_loss 0.669 generator_loss 0.777\n",
      "Epoch 58 Iteration 235: discriminator_loss 0.687 generator_loss 0.731\n",
      "Epoch 59 Iteration 100: discriminator_loss 0.717 generator_loss 0.696\n",
      "Epoch 59 Iteration 200: discriminator_loss 0.704 generator_loss 0.739\n",
      "Epoch 59 Iteration 235: discriminator_loss 0.710 generator_loss 0.811\n",
      "Model saved.\n",
      "Epoch 60 Iteration 100: discriminator_loss 0.702 generator_loss 0.715\n",
      "Epoch 60 Iteration 200: discriminator_loss 0.702 generator_loss 0.738\n",
      "Epoch 60 Iteration 235: discriminator_loss 0.683 generator_loss 0.780\n",
      "Epoch 61 Iteration 100: discriminator_loss 0.689 generator_loss 0.749\n",
      "Epoch 61 Iteration 200: discriminator_loss 0.692 generator_loss 0.776\n",
      "Epoch 61 Iteration 235: discriminator_loss 0.702 generator_loss 0.757\n",
      "Epoch 62 Iteration 100: discriminator_loss 0.699 generator_loss 0.733\n",
      "Epoch 62 Iteration 200: discriminator_loss 0.697 generator_loss 0.709\n",
      "Epoch 62 Iteration 235: discriminator_loss 0.712 generator_loss 0.655\n",
      "Epoch 63 Iteration 100: discriminator_loss 0.680 generator_loss 0.729\n",
      "Epoch 63 Iteration 200: discriminator_loss 0.676 generator_loss 0.740\n",
      "Epoch 63 Iteration 235: discriminator_loss 0.690 generator_loss 0.771\n",
      "Epoch 64 Iteration 100: discriminator_loss 0.689 generator_loss 0.788\n",
      "Epoch 64 Iteration 200: discriminator_loss 0.710 generator_loss 0.707\n",
      "Epoch 64 Iteration 235: discriminator_loss 0.678 generator_loss 0.712\n",
      "Epoch 65 Iteration 100: discriminator_loss 0.656 generator_loss 0.811\n",
      "Epoch 65 Iteration 200: discriminator_loss 0.667 generator_loss 0.791\n",
      "Epoch 65 Iteration 235: discriminator_loss 0.680 generator_loss 0.778\n",
      "Epoch 66 Iteration 100: discriminator_loss 0.707 generator_loss 0.705\n",
      "Epoch 66 Iteration 200: discriminator_loss 0.705 generator_loss 0.758\n",
      "Epoch 66 Iteration 235: discriminator_loss 0.691 generator_loss 0.736\n",
      "Epoch 67 Iteration 100: discriminator_loss 0.655 generator_loss 0.791\n",
      "Epoch 67 Iteration 200: discriminator_loss 0.697 generator_loss 0.777\n",
      "Epoch 67 Iteration 235: discriminator_loss 0.687 generator_loss 0.724\n",
      "Epoch 68 Iteration 100: discriminator_loss 0.703 generator_loss 0.757\n",
      "Epoch 68 Iteration 200: discriminator_loss 0.692 generator_loss 0.764\n",
      "Epoch 68 Iteration 235: discriminator_loss 0.679 generator_loss 0.755\n",
      "Epoch 69 Iteration 100: discriminator_loss 0.693 generator_loss 0.749\n",
      "Epoch 69 Iteration 200: discriminator_loss 0.697 generator_loss 0.765\n",
      "Epoch 69 Iteration 235: discriminator_loss 0.681 generator_loss 0.727\n",
      "Model saved.\n",
      "Epoch 70 Iteration 100: discriminator_loss 0.704 generator_loss 0.710\n",
      "Epoch 70 Iteration 200: discriminator_loss 0.691 generator_loss 0.719\n",
      "Epoch 70 Iteration 235: discriminator_loss 0.715 generator_loss 0.723\n",
      "Epoch 71 Iteration 100: discriminator_loss 0.709 generator_loss 0.766\n",
      "Epoch 71 Iteration 200: discriminator_loss 0.696 generator_loss 0.715\n",
      "Epoch 71 Iteration 235: discriminator_loss 0.699 generator_loss 0.722\n",
      "Epoch 72 Iteration 100: discriminator_loss 0.715 generator_loss 0.781\n",
      "Epoch 72 Iteration 200: discriminator_loss 0.693 generator_loss 0.724\n",
      "Epoch 72 Iteration 235: discriminator_loss 0.713 generator_loss 0.704\n",
      "Epoch 73 Iteration 100: discriminator_loss 0.691 generator_loss 0.742\n",
      "Epoch 73 Iteration 200: discriminator_loss 0.700 generator_loss 0.725\n",
      "Epoch 73 Iteration 235: discriminator_loss 0.688 generator_loss 0.759\n",
      "Epoch 74 Iteration 100: discriminator_loss 0.699 generator_loss 0.768\n",
      "Epoch 74 Iteration 200: discriminator_loss 0.693 generator_loss 0.713\n",
      "Epoch 74 Iteration 235: discriminator_loss 0.704 generator_loss 0.707\n",
      "Epoch 75 Iteration 100: discriminator_loss 0.696 generator_loss 0.732\n",
      "Epoch 75 Iteration 200: discriminator_loss 0.699 generator_loss 0.739\n",
      "Epoch 75 Iteration 235: discriminator_loss 0.717 generator_loss 0.764\n",
      "Epoch 76 Iteration 100: discriminator_loss 0.709 generator_loss 0.743\n",
      "Epoch 76 Iteration 200: discriminator_loss 0.709 generator_loss 0.697\n",
      "Epoch 76 Iteration 235: discriminator_loss 0.688 generator_loss 0.762\n",
      "Epoch 77 Iteration 100: discriminator_loss 0.713 generator_loss 0.735\n",
      "Epoch 77 Iteration 200: discriminator_loss 0.709 generator_loss 0.749\n",
      "Epoch 77 Iteration 235: discriminator_loss 0.675 generator_loss 0.720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Iteration 100: discriminator_loss 0.708 generator_loss 0.752\n",
      "Epoch 78 Iteration 200: discriminator_loss 0.693 generator_loss 0.712\n",
      "Epoch 78 Iteration 235: discriminator_loss 0.694 generator_loss 0.778\n",
      "Epoch 79 Iteration 100: discriminator_loss 0.679 generator_loss 0.760\n",
      "Epoch 79 Iteration 200: discriminator_loss 0.701 generator_loss 0.720\n",
      "Epoch 79 Iteration 235: discriminator_loss 0.705 generator_loss 0.758\n",
      "Model saved.\n",
      "Epoch 80 Iteration 100: discriminator_loss 0.700 generator_loss 0.709\n",
      "Epoch 80 Iteration 200: discriminator_loss 0.667 generator_loss 0.729\n",
      "Epoch 80 Iteration 235: discriminator_loss 0.685 generator_loss 0.732\n",
      "Epoch 81 Iteration 100: discriminator_loss 0.692 generator_loss 0.737\n",
      "Epoch 81 Iteration 200: discriminator_loss 0.650 generator_loss 0.766\n",
      "Epoch 81 Iteration 235: discriminator_loss 0.663 generator_loss 0.780\n",
      "Epoch 82 Iteration 100: discriminator_loss 0.709 generator_loss 0.704\n",
      "Epoch 82 Iteration 200: discriminator_loss 0.697 generator_loss 0.705\n",
      "Epoch 82 Iteration 235: discriminator_loss 0.695 generator_loss 0.661\n",
      "Epoch 83 Iteration 100: discriminator_loss 0.674 generator_loss 0.732\n",
      "Epoch 83 Iteration 200: discriminator_loss 0.676 generator_loss 0.737\n",
      "Epoch 83 Iteration 235: discriminator_loss 0.704 generator_loss 0.709\n",
      "Epoch 84 Iteration 100: discriminator_loss 0.710 generator_loss 0.697\n",
      "Epoch 84 Iteration 200: discriminator_loss 0.700 generator_loss 0.728\n",
      "Epoch 84 Iteration 235: discriminator_loss 0.710 generator_loss 0.702\n",
      "Epoch 85 Iteration 100: discriminator_loss 0.692 generator_loss 0.749\n",
      "Epoch 85 Iteration 200: discriminator_loss 0.703 generator_loss 0.749\n",
      "Epoch 85 Iteration 235: discriminator_loss 0.701 generator_loss 0.716\n",
      "Epoch 86 Iteration 100: discriminator_loss 0.688 generator_loss 0.755\n",
      "Epoch 86 Iteration 200: discriminator_loss 0.721 generator_loss 0.674\n",
      "Epoch 86 Iteration 235: discriminator_loss 0.731 generator_loss 0.672\n",
      "Epoch 87 Iteration 100: discriminator_loss 0.697 generator_loss 0.709\n",
      "Epoch 87 Iteration 200: discriminator_loss 0.680 generator_loss 0.714\n",
      "Epoch 87 Iteration 235: discriminator_loss 0.697 generator_loss 0.689\n",
      "Epoch 88 Iteration 100: discriminator_loss 0.680 generator_loss 0.726\n",
      "Epoch 88 Iteration 200: discriminator_loss 0.701 generator_loss 0.730\n",
      "Epoch 88 Iteration 235: discriminator_loss 0.679 generator_loss 0.728\n",
      "Epoch 89 Iteration 100: discriminator_loss 0.716 generator_loss 0.697\n",
      "Epoch 89 Iteration 200: discriminator_loss 0.701 generator_loss 0.718\n",
      "Epoch 89 Iteration 235: discriminator_loss 0.718 generator_loss 0.700\n",
      "Model saved.\n",
      "Epoch 90 Iteration 100: discriminator_loss 0.687 generator_loss 0.716\n",
      "Epoch 90 Iteration 200: discriminator_loss 0.693 generator_loss 0.716\n",
      "Epoch 90 Iteration 235: discriminator_loss 0.691 generator_loss 0.720\n",
      "Epoch 91 Iteration 100: discriminator_loss 0.700 generator_loss 0.700\n",
      "Epoch 91 Iteration 200: discriminator_loss 0.692 generator_loss 0.739\n",
      "Epoch 91 Iteration 235: discriminator_loss 0.699 generator_loss 0.692\n",
      "Epoch 92 Iteration 100: discriminator_loss 0.712 generator_loss 0.704\n",
      "Epoch 92 Iteration 200: discriminator_loss 0.679 generator_loss 0.729\n",
      "Epoch 92 Iteration 235: discriminator_loss 0.678 generator_loss 0.846\n",
      "Epoch 93 Iteration 100: discriminator_loss 0.693 generator_loss 0.765\n",
      "Epoch 93 Iteration 200: discriminator_loss 0.703 generator_loss 0.723\n",
      "Epoch 93 Iteration 235: discriminator_loss 0.711 generator_loss 0.728\n",
      "Epoch 94 Iteration 100: discriminator_loss 0.660 generator_loss 0.779\n",
      "Epoch 94 Iteration 200: discriminator_loss 0.691 generator_loss 0.735\n",
      "Epoch 94 Iteration 235: discriminator_loss 0.669 generator_loss 0.758\n",
      "Epoch 95 Iteration 100: discriminator_loss 0.702 generator_loss 0.711\n",
      "Epoch 95 Iteration 200: discriminator_loss 0.698 generator_loss 0.707\n",
      "Epoch 95 Iteration 235: discriminator_loss 0.676 generator_loss 0.710\n",
      "Epoch 96 Iteration 100: discriminator_loss 0.691 generator_loss 0.746\n",
      "Epoch 96 Iteration 200: discriminator_loss 0.696 generator_loss 0.740\n",
      "Epoch 96 Iteration 235: discriminator_loss 0.695 generator_loss 0.722\n",
      "Epoch 97 Iteration 100: discriminator_loss 0.685 generator_loss 0.740\n",
      "Epoch 97 Iteration 200: discriminator_loss 0.655 generator_loss 0.771\n",
      "Epoch 97 Iteration 235: discriminator_loss 0.683 generator_loss 0.702\n",
      "Epoch 98 Iteration 100: discriminator_loss 0.715 generator_loss 0.758\n",
      "Epoch 98 Iteration 200: discriminator_loss 0.705 generator_loss 0.697\n",
      "Epoch 98 Iteration 235: discriminator_loss 0.704 generator_loss 0.679\n",
      "Epoch 99 Iteration 100: discriminator_loss 0.707 generator_loss 0.699\n",
      "Epoch 99 Iteration 200: discriminator_loss 0.681 generator_loss 0.759\n",
      "Epoch 99 Iteration 235: discriminator_loss 0.684 generator_loss 0.752\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Network training procedure\n",
    "Every step both the loss for disciminator and generator is updated\n",
    "Discriminator aims to classify reals and fakes\n",
    "Generator aims to generate images as realistic as possible\n",
    "\n",
    "\"\"\"\n",
    "for epoch in range(epochs):\n",
    "    for idx, (imgs, _) in enumerate(train_dataloader):\n",
    "        idx += 1\n",
    "\n",
    "        # Training the discriminator\n",
    "        # Real inputs are actual images of the MNIST dataset\n",
    "        # Fake inputs are from the generator\n",
    "        # Real inputs should be classified as 1 and fake as 0\n",
    "        real_inputs = imgs.to(device)\n",
    "        real_outputs = D(real_inputs) #Discrimination on real images\n",
    "        real_label = torch.ones(real_inputs.shape[0], 1).to(device)\n",
    "\n",
    "        noise = (torch.rand(real_inputs.shape[0], 128) - 0.5) / 0.5\n",
    "        noise = noise.to(device)\n",
    "        fake_inputs = G(noise)        #Generation of false images\n",
    "        fake_outputs = D(fake_inputs) #Discrimination on false images\n",
    "        fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)\n",
    "\n",
    "        outputs = torch.cat((real_outputs, fake_outputs), 0)\n",
    "        targets = torch.cat((real_label, fake_label), 0)\n",
    "\n",
    "        D_loss = loss(outputs, targets)\n",
    "        D_optimizer.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        # Training the generator\n",
    "        # For generator, goal is to make the discriminator believe everything is 1\n",
    "        noise = (torch.rand(real_inputs.shape[0], 128)-0.5)/0.5\n",
    "        noise = noise.to(device)\n",
    "\n",
    "        fake_inputs = G(noise)         #Generate images\n",
    "        fake_outputs = D(fake_inputs)  #Classify fake images\n",
    "        fake_targets = torch.ones([fake_inputs.shape[0], 1]).to(device)\n",
    "        G_loss = loss(fake_outputs, fake_targets)\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        if idx % 100 == 0 or idx == len(train_dataloader):\n",
    "            print('Epoch {} Iteration {}: discriminator_loss {:.3f} generator_loss {:.3f}'.format(epoch, idx, D_loss.item(), G_loss.item()))\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(G, 'Generator_epoch_{}.pth'.format(epoch))\n",
    "        print('Model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43c4c81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f2d3da3160>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake = G(noise)[0].squeeze().detach().numpy()\n",
    "plt.imshow(fake, cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a3ff48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e655516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3acbf55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_outputs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "760bafac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82ba9ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08becda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42970b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
